{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse et Système de Recommandation de Chansons\n",
    "\n",
    "Ce notebook reprend et adapte le script `recommendation_system.py` pour une exécution interactive. Il compare deux approches de vectorisation de texte (TF-IDF et Embeddings) pour un système de recommandation de chansons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cellule 0: Imports et Configuration NLTK ---\n",
      "Stopwords NLTK déjà téléchargés.\n",
      "Librairies importées et stopwords configurés.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Configuration initiale de NLTK ---\n",
    "print('--- Cellule 0: Imports et Configuration NLTK ---')\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    print('Stopwords NLTK déjà téléchargés.')\n",
    "except LookupError:\n",
    "    print('Téléchargement des stopwords NLTK...')\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "stop_words_fr = set(stopwords.words('french'))\n",
    "print('Librairies importées et stopwords configurés.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Chargement et Prétraitement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cellule 1: Définition de la fonction de nettoyage ---\n",
      "Fonction clean_text définie.\n",
      "\n",
      "--- Cellule 1.1: Chargement et nettoyage du corpus ---\n",
      "Chargement des données depuis : /content/TP2/chansons\n",
      "ERREUR: Aucun fichier .txt n'a été trouvé dans le dossier '/content/TP2/chansons'.\n",
      "Veuillez vérifier que le chemin est correct et que les fichiers existent.\n"
     ]
    }
   ],
   "source": [
    "print('\\n--- Cellule 1: Définition de la fonction de nettoyage ---')\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words_fr]\n",
    "    return ' '.join(words)\n",
    "\n",
    "print('Fonction clean_text définie.')\n",
    "\n",
    "\n",
    "print('\\n--- Cellule 1.1: Chargement et nettoyage du corpus ---')\n",
    "# Le chemin vers le dossier 'TP2/chansons' est supposé être relatif au dossier où le notebook est exécuté\n",
    "chansons_directory = os.path.join(os.getcwd(), 'TP2', 'chansons')\n",
    "\n",
    "print(f\"Chargement des données depuis : {chansons_directory}\")\n",
    "filepaths = glob.glob(os.path.join(chansons_directory, '*.txt'))\n",
    "\n",
    "if not filepaths:\n",
    "    print(f\"ERREUR: Aucun fichier .txt n'a été trouvé dans le dossier '{chansons_directory}'.\")\n",
    "    print(\"Veuillez vérifier que le chemin est correct et que les fichiers existent.\")\n",
    "    df_chansons = pd.DataFrame()\n",
    "else:\n",
    "    chansons_data = []\n",
    "    for filepath in filepaths:\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                lyrics = f.read()\n",
    "            title = os.path.basename(filepath).replace('.txt', '').replace('_', ' ').title()\n",
    "            chansons_data.append({'titre': title, 'paroles': lyrics})\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur de lecture du fichier {filepath}: {e}\")\n",
    "\n",
    "    df_chansons = pd.DataFrame(chansons_data)\n",
    "    print(f\"{len(df_chansons)} chansons chargées.\")\n",
    "    \n",
    "    print('Nettoyage des paroles en cours...')\n",
    "    df_chansons['paroles_cleaned'] = df_chansons['paroles'].apply(clean_text)\n",
    "    \n",
    "    print('Affichage des 5 premières lignes du DataFrame:')\n",
    "    display(df_chansons.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Vectorisation (Comparaison des deux approches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche 1: TF-IDF (Classique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n--- Cellule 2.1: Vectorisation avec TF-IDF ---')\n",
    "def vectorize_tfidf(texts):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    matrix = vectorizer.fit_transform(texts)\n",
    "    print(f\"Matrice TF-IDF créée. Dimensions : {matrix.shape}\")\n",
    "    return matrix\n",
    "\n",
    "if not df_chansons.empty:\n",
    "    tfidf_matrix = vectorize_tfidf(df_chansons['paroles_cleaned'])\n",
    "    cosine_sim_tfidf = cosine_similarity(tfidf_matrix)\n",
    "else:\n",
    "    tfidf_matrix = None\n",
    "    cosine_sim_tfidf = None\n",
    "    print('Le DataFrame est vide, la vectorisation TF-IDF est annulée.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche 2: Embeddings Sémantiques (Moderne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n--- Cellule 2.2: Vectorisation avec Embeddings Sémantiques ---')\n",
    "def vectorize_embeddings(texts):\n",
    "    try:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "    except ImportError:\n",
    "        print(\"ERREUR: La librairie 'sentence-transformers' n'est pas installée.\")\n",
    "        print(\"Veuillez l'installer avec la commande : pip install sentence-transformers\")\n",
    "        return None\n",
    "\n",
    "    model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "    print(\"Modèle d'embedding chargé. Création des embeddings en cours...\")\n",
    "    embeddings = model.encode(texts.tolist(), show_progress_bar=True)\n",
    "    print(f\"Matrice d'embeddings créée. Dimensions : {embeddings.shape}\")\n",
    "    return embeddings\n",
    "\n",
    "if not df_chansons.empty:\n",
    "    embedding_matrix = vectorize_embeddings(df_chansons['paroles_cleaned'])\n",
    "    if embedding_matrix is not None:\n",
    "        cosine_sim_embed = cosine_similarity(embedding_matrix)\n",
    "    else:\n",
    "        cosine_sim_embed = None\n",
    "else:\n",
    "    embedding_matrix = None\n",
    "    cosine_sim_embed = None\n",
    "    print('Le DataFrame est vide, la vectorisation par embeddings est annulée.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Logique de Recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n--- Cellule 3.1: Définition de la fonction de recommandation ---')\n",
    "def get_recommendations(song_title, df, similarity_matrix, top_n=5):\n",
    "    if song_title not in df['titre'].values:\n",
    "        print(f\"ERREUR: Le titre '{song_title}' n'est pas dans la liste des chansons.\")\n",
    "        return\n",
    "\n",
    "    idx = df.index[df['titre'] == song_title].tolist()[0]\n",
    "    sim_scores = list(enumerate(similarity_matrix[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_song_indices = [i[0] for i in sim_scores[1:top_n+1]]\n",
    "    \n",
    "    recommendations = df['titre'].iloc[top_song_indices].tolist()\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "if not df_chansons.empty:\n",
    "    # Choisir une chanson pour tester les recommandations (ici, la première du DataFrame)\n",
    "    test_song_title = df_chansons['titre'].iloc[0]\n",
    "    print(f\"\\n--- Cellule 3.2: Recommandations pour '{test_song_title}' ---\")\n",
    "\n",
    "    # --- Recommandations avec TF-IDF ---\n",
    "    if cosine_sim_tfidf is not None:\n",
    "        print(\"\\n*** RÉSULTATS AVEC TF-IDF ***\")\n",
    "        tfidf_recs = get_recommendations(test_song_title, df_chansons, cosine_sim_tfidf)\n",
    "        for i, rec_title in enumerate(tfidf_recs):\n",
    "            print(f\"{i+1}. {rec_title}\")\n",
    "\n",
    "    # --- Recommandations avec Embeddings ---\n",
    "    if cosine_sim_embed is not None:\n",
    "        print(\"\\n*** RÉSULTATS AVEC EMBEDDINGS (APPROCHE MODERNE) ***\")\n",
    "        embed_recs = get_recommendations(test_song_title, df_chansons, cosine_sim_embed)\n",
    "        for i, rec_title in enumerate(embed_recs):\n",
    "            print(f\"{i+1}. {rec_title}\")\n",
    "else:\n",
    "    print('Le DataFrame est vide, les recommandations ne peuvent pas être générées.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Visualisation des Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n--- Cellule 4.1: Visualisation des Embeddings avec PCA ---')\n",
    "def visualize_embeddings_pca(embedding_matrix, df):\n",
    "    if embedding_matrix is None or df.empty:\n",
    "        print(\"Matrice d'embeddings ou DataFrame vide, impossible de visualiser.\")\n",
    "        return\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    embeddings_2d = pca.fit_transform(embedding_matrix)\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.7)\n",
    "    \n",
    "    # Annoter quelques points pour la lisibilité\n",
    "    # S'assure que len(df) n'est pas 0 avant la division\n",
    "    annotation_interval = max(1, len(df) // 10) # Annoter environ 10% des chansons\n",
    "    for i, title in enumerate(df['titre']):\n",
    "        if i % annotation_interval == 0:\n",
    "             plt.annotate(title, (embeddings_2d[i, 0], embeddings_2d[i, 1]), alpha=0.8)\n",
    "    \n",
    "    plt.title(\"Visualisation des Chansons (Embeddings projetés en 2D via PCA)\")\n",
    "    plt.xlabel(\"Composante Principale 1\")\n",
    "    plt.ylabel(\"Composante Principale 2\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    output_filename = \"visualisation_chansons_pca_notebook.png\"\n",
    "    plt.savefig(output_filename)\n",
    "    print(f\"Le graphique de visualisation a été sauvegardé sous : {output_filename}\")\n",
    "    plt.show() # Pour afficher le graphique directement dans le notebook\n",
    "\n",
    "\n",
    "if not df_chansons.empty and embedding_matrix is not None:\n",
    "    visualize_embeddings_pca(embedding_matrix, df_chansons)\n",
    "else:\n",
    "    print('Visualisation annulée car le DataFrame ou la matrice d\\'embeddings est vide.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
